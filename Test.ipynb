{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Downloading the dataset\n",
    "dataset = load_dataset(\"hf-vision/chest-xray-pneumonia\")\n",
    "\n",
    "# Accessing the train, validation, and test splits of the dataset\n",
    "train_data = dataset[\"train\"]\n",
    "validation_data = dataset[\"validation\"]\n",
    "test_data = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating train, validation, and test data to find unique labels\n",
    "all_data = train_data[\"label\"] + validation_data[\"label\"] + test_data[\"label\"]\n",
    "\n",
    "# Finding unique labels\n",
    "unique_labels = set(all_data)\n",
    "\n",
    "# Print unique labels\n",
    "print(\"Unique labels in the dataset:\", unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the number of labels for Pneumonia and normal cases in train data\n",
    "train_pneumonia_count = sum(1 for label in train_data[\"label\"] if label == 1)\n",
    "train_normal_count = sum(1 for label in train_data[\"label\"] if label == 0)\n",
    "\n",
    "# Counting the number of labels for Pneumonia and normal cases in validation data\n",
    "validation_pneumonia_count = sum(1 for label in validation_data[\"label\"] if label == 1)\n",
    "validation_normal_count = sum(1 for label in validation_data[\"label\"] if label == 0)\n",
    "\n",
    "# Counting the number of labels for Pneumonia and normal cases in test data\n",
    "test_pneumonia_count = sum(1 for label in test_data[\"label\"] if label == 1)\n",
    "test_normal_count = sum(1 for label in test_data[\"label\"] if label == 0)\n",
    "\n",
    "# Print the counts\n",
    "print(\"Train Data:\")\n",
    "print(\"Pneumonia count:\", train_pneumonia_count)\n",
    "print(\"Normal count:\", train_normal_count)\n",
    "print(\"\\nValidation Data:\")\n",
    "print(\"Pneumonia count:\", validation_pneumonia_count)\n",
    "print(\"Normal count:\", validation_normal_count)\n",
    "print(\"\\nTest Data:\")\n",
    "print(\"Pneumonia count:\", test_pneumonia_count)\n",
    "print(\"Normal count:\", test_normal_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Downloading the dataset\n",
    "dataset1 = load_dataset(\"alkzar90/NIH-Chest-X-ray-dataset\", 'image-classification')\n",
    "\n",
    "# Accessing the train split of the dataset\n",
    "train_data1 = dataset1[\"train\"]\n",
    "\n",
    "# Filter out data where label is 0\n",
    "train_data_no_finding = train_data1.filter(lambda example: example[\"label\"] == 0)\n",
    "\n",
    "# Accessing the validation split of the dataset\n",
    "validation_data1 = dataset1[\"validation\"]\n",
    "\n",
    "# Filter out data where label is 0\n",
    "validation_data_no_finding = validation_data1.filter(lambda example: example[\"label\"] == 0)\n",
    "\n",
    "# Accessing the test split of the dataset\n",
    "test_data1 = dataset1[\"test\"]\n",
    "\n",
    "# Filter out data where label is 0\n",
    "test_data_no_finding = test_data1.filter(lambda example: example[\"label\"] == 0)\n",
    "\n",
    "# Print the lengths of filtered datasets\n",
    "print(\"Number of examples in Train Data with no finding:\", len(train_data_no_finding))\n",
    "print(\"Number of examples in Validation Data with no finding:\", len(validation_data_no_finding))\n",
    "print(\"Number of examples in Test Data with no finding:\", len(test_data_no_finding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "# Downloading the datasets\n",
    "hf_chest_xray_dataset = load_dataset(\"hf-vision/chest-xray-pneumonia\")\n",
    "alkzar90_dataset = load_dataset(\"alkzar90/NIH-Chest-X-ray-dataset\", 'image-classification')\n",
    "\n",
    "# Filter out \"no finding\" data from alkzar90 dataset\n",
    "alkzar90_no_finding_data = alkzar90_dataset[\"train\"].filter(lambda example: example[\"label\"] == 0)\n",
    "\n",
    "# Filter out normal data from hf/chest_xray dataset\n",
    "hf_chest_xray_normal_data = hf_chest_xray_dataset[\"train\"].filter(lambda example: example[\"label\"] == 0)\n",
    "\n",
    "# Concatenate the two datasets\n",
    "merged_normal_data = Dataset.concatenate(alkzar90_no_finding_data, hf_chest_xray_normal_data)\n",
    "\n",
    "# Accessing the pneumonia data from hf/chest_xray dataset\n",
    "hf_chest_xray_pneumonia_data = hf_chest_xray_dataset[\"train\"].filter(lambda example: example[\"label\"] == 1)\n",
    "\n",
    "# Print the lengths of merged datasets\n",
    "print(\"Number of examples in Merged Normal Data:\", len(merged_normal_data))\n",
    "print(\"Number of examples in Pneumonia Data:\", len(hf_chest_xray_pneumonia_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out \"no finding\" data from alkzar90 dataset for train, test, and validation splits\n",
    "alkzar90_test_no_finding_data = alkzar90_dataset[\"test\"].filter(lambda example: example[\"label\"] == 0)\n",
    "alkzar90_validation_no_finding_data = alkzar90_dataset[\"validation\"].filter(lambda example: example[\"label\"] == 0)\n",
    "\n",
    "# Filter out normal data from hf/chest_xray dataset for train, test, and validation splits\n",
    "hf_chest_xray_test_normal_data = hf_chest_xray_dataset[\"test\"].filter(lambda example: example[\"label\"] == 0)\n",
    "hf_chest_xray_validation_normal_data = hf_chest_xray_dataset[\"validation\"].filter(lambda example: example[\"label\"] == 0)\n",
    "\n",
    "# Concatenate the two datasets for train, test, and validation splits\n",
    "merged_test_normal_data = Dataset.concatenate(alkzar90_test_no_finding_data, hf_chest_xray_test_normal_data)\n",
    "merged_validation_normal_data = Dataset.concatenate(alkzar90_validation_no_finding_data, hf_chest_xray_validation_normal_data)\n",
    "\n",
    "# Accessing the pneumonia data from hf/chest_xray dataset for train, test, and validation splits\n",
    "hf_chest_xray_test_pneumonia_data = hf_chest_xray_dataset[\"test\"].filter(lambda example: example[\"label\"] == 1)\n",
    "hf_chest_xray_validation_pneumonia_data = hf_chest_xray_dataset[\"validation\"].filter(lambda example: example[\"label\"] == 1)\n",
    "\n",
    "# Print the lengths of merged datasets\n",
    "print(\"Number of examples in Merged Test Normal Data:\", len(merged_test_normal_data))\n",
    "print(\"Number of examples in Merged Validation Normal Data:\", len(merged_validation_normal_data))\n",
    "print(\"Number of examples in Test Pneumonia Data:\", len(hf_chest_xray_test_pneumonia_data))\n",
    "print(\"Number of examples in Validation Pneumonia Data:\", len(hf_chest_xray_validation_pneumonia_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define image dimensions\n",
    "img_height, img_width = 224, 224\n",
    "\n",
    "# Prepare training, validation, and test data\n",
    "train_data = merged_normal_data.map(lambda x: {\"image\": tf.image.resize(x[\"image\"], (img_height, img_width)), \"label\": 0}).concatenate(hf_chest_xray_train_pneumonia_data.map(lambda x: {\"image\": tf.image.resize(x[\"image\"], (img_height, img_width)), \"label\": 1}))\n",
    "test_data = merged_test_normal_data.map(lambda x: {\"image\": tf.image.resize(x[\"image\"], (img_height, img_width)), \"label\": 0}).concatenate(hf_chest_xray_test_pneumonia_data.map(lambda x: {\"image\": tf.image.resize(x[\"image\"], (img_height, img_width)), \"label\": 1}))\n",
    "validation_data = merged_validation_normal_data.map(lambda x: {\"image\": tf.image.resize(x[\"image\"], (img_height, img_width)), \"label\": 0}).concatenate(hf_chest_xray_validation_pneumonia_data.map(lambda x: {\"image\": tf.image.resize(x[\"image\"], (img_height, img_width)), \"label\": 1}))\n",
    "\n",
    "# Shuffle and batch the data\n",
    "train_data = train_data.shuffle(1000).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_data = test_data.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "validation_data = validation_data.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Load pre-trained ResNet50 model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "\n",
    "# Add custom classifier head\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)  # Sigmoid activation for binary classification\n",
    "\n",
    "# Combine base model with custom head\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze layers in base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_data, validation_data=validation_data, epochs=10)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# shutil.rmtree('/Users/simransarawagi/.cache/huggingface/datasets/downloads')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
